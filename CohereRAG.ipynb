{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJrLEHiemiC3"
      },
      "outputs": [],
      "source": [
        "!pip install virtualenv\n",
        "!mkdir my_virtualenv\n",
        "%cd my_virtualenv\n",
        "!virtualenv my_env\n",
        "!source my_env/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU cohere\n",
        "!pip install -qU langchain\n",
        "!pip install -qU pypdf\n",
        "!pip install -qU tiktoken\n",
        "!pip install -qU chromadb"
      ],
      "metadata": {
        "id": "u7Z3KS4Wm3oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install weasyprint\n",
        "! pip install pdfkit\n",
        "! pip install wkhtmltopdf"
      ],
      "metadata": {
        "id": "IsT7G3Mim8fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "cohere_key = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU4KgbE1ndPs",
        "outputId": "1c867428-cecd-4e2b-f525-c3b3d5a1ca68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "co = cohere.Client(cohere_key)\n",
        "response = co.generate(\n",
        "  model='command-nightly',\n",
        "  prompt='write a description about Cohere',\n",
        "  max_tokens=300,\n",
        "  temperature=0.9,\n",
        "  k=0,\n",
        "  p=0.75,\n",
        "  stop_sequences=[],\n",
        "  return_likelihoods='NONE')\n",
        "print('Prediction: {}'.format(response.generations[0].text))"
      ],
      "metadata": {
        "id": "qcMmu0IUnoBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.generations[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "6f2BsuW6n3-z",
        "outputId": "d116c4af-f48f-449f-f975-e2a380a1a656"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Cohere is a company that specializes in bringing the power of large language models to businesses. Cohere's cutting-edge technology empowers businesses to create tailored, data-driven solutions that enable them to optimize operations, automate customer interactions, and enhance content generation, all while delivering exceptional user experiences. \\n\\nThe company's innovative approach to Natural Language Processing (NLP) has allowed businesses to break through the limitations of traditional language models, unlocking new capabilities and driving digital transformation across a range of industries. With a focus on helping businesses to future-proof their operations, Cohere's advanced language models and NLP tools are revolutionizing the way companies operate, providing an efficient and tailored experience. \\n\\nCohere's mission is to empower every business to leverage the latest and most effective language AI. The company aims to do this by providing an accessible, reliable, and robust platform with the support and tools needed to enable successful and efficient integration of language models into businesses. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import CohereEmbeddings\n",
        "embeddings = CohereEmbeddings(cohere_api_key=cohere_key)\n",
        "text = \"This is a test document.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "doc_result = embeddings.embed_documents([text])\n",
        "print(doc_result)"
      ],
      "metadata": {
        "id": "-6xohwx_n-B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWMFAzpxodaa",
        "outputId": "fbb46c90-44cf-4a4f-9d43-e3f5061f3e70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(doc_result).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXKrYIvsohhD",
        "outputId": "5a65c451-a608-4c14-8e0a-c1b1b40d0a7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4096)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weasyprint\n",
        "import os"
      ],
      "metadata": {
        "id": "861k_z7fov8p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pdf(url):\n",
        "  pdf = weasyprint.HTML(url).write_pdf()\n",
        "  output_dir=\"pdf_dir\"\n",
        "  if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "  file_path = os.path.join(output_dir,'sample.pdf')\n",
        "  with open(file_path,'wb') as f:\n",
        "    f.write(pdf)"
      ],
      "metadata": {
        "id": "fLVQAquIozNx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://medium.com/@mygreatlearning/50-nlp-interview-questions-and-answers-with-explanations-6ea4af32cbda\"\n",
        "create_pdf(url)"
      ],
      "metadata": {
        "id": "K2BFrX2ppEub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader,PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import VectorDBQA\n",
        "from langchain.llms import Cohere\n",
        "import os\n",
        "directory = \"/content/my_virtualenv/pdf_dir\"\n",
        "loader = PyPDFDirectoryLoader(directory)\n",
        "#loader = PyPDFLoader(\"/content/drive/MyDrive/ChatGPT/Shared/ChromaDB/Data/Australia - Wikipedia2.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = cohere_key"
      ],
      "metadata": {
        "id": "naeV-O4ApKx3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = CohereEmbeddings()\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "crUgXImNqiAb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_QRUkV7qnLD",
        "outputId": "f04691a3-6c66-466e-ed50-479e6a13cc84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='13. T okens are converted into numbers before giving to\\nany Neural Networka. True\\nb. False\\nAns:  a)\\nIn NLP, all words are converted into a number before feeding to a Neural Network.\\n14. identify the odd one outa. nltk\\nb. scikit learn\\nc. SpaCy\\nd. BERT\\nAns:  d)\\nAll the ones mentioned are NLP libraries except BERT, which is a word embedding\\n15. TF-IDF helps you to establish?a. most frequently occurring word in the document\\nb. most important word in the document\\nAns:  b)\\nTF-IDF helps to establish how important a particular word is in the context of the\\ndocument corpus. TF-IDF takes into account the number of times the word appears\\nin the document and offset by the number of documents that appear in the corpus.\\nTF is the frequency of term divided by a total number of terms in the document.\\nIDF is obtained by dividing the total number of documents by the number of\\ndocuments containing the term and then taking the logarithm of that quotient.\\nTf.idf is then the multiplication of two values TF and IDF.\\nSuppose that we have term count tables of a corpus consisting of only two\\ndocuments, as listed here\\nThe calculation of tf–idf for the term “this” is performed as follows:\\nfor “this”\\n— — — –\\ntf(“this”, d1) = 1/5 = 0.2\\ntf(“this”, d2) = 1/7 = 0.14\\nidf(“this”, D) = log (2/2) =0\\nhence tf-idf\\ntfidf(“this”, d1, D) = 0.2* 0 = 0\\ntfidf(“this”, d2, D) = 0.14* 0 = 0\\nfor “example”\\n— — — — \\ntf(“example”, d1) = 0/5 = 0\\ntf(“example”, d2) = 3/7 = 0.43\\nidf(“example”, D) = log(2/1) = 0.301\\ntfidf(“example”, d1, D) = tf(“example”, d1) * idf(“example”, D) = 0 * 0.301 = 0\\ntfidf(“example”, d2, D) = tf(“example”, d2) * idf(“example”, D) = 0.43 * 0.301 = 0.129• \\n• \\n•', metadata={'source': '/content/my_virtualenv/pdf_dir/sample.pdf', 'page': 5})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CUQLADYqpes",
        "outputId": "b9de249e-cf5c-4044-ee7a-0ae31547fb44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x7fc4466e31c0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = VectorDBQA.from_chain_type(llm=Cohere(), chain_type=\"stuff\", vectorstore=db)\n",
        "query = \"Tell me about NLP.\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "_9Gez700qw_E",
        "outputId": "c2c2f845-a765-4e58-e1d2-f054991efc90"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py:256: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. Its objective is to enable machines to comprehend, analyze, and interpret human language with the purpose of producing actionable insights. NLP combines computational linguistics, a branch of linguistics that deals with language and their syntax as well as semantics, with statistical, machine, and deep learning to enable intuitive communication between humans and machines. \\n\\nNLP is important because it allows machines to understand and process human language in order to perform tasks such as text translation, sentiment analysis, and text summarization. These tasks require the machine to understand the context, semantics, and syntax of the language in order to provide an accurate response.\\n\\nNLP is widely used in various industries such as healthcare, finance, and customer support to name a few. Its application is vast, ranging from language translation to improving search engine results and even helping people with disabilities to overcome communication barriers. \\n\\nThere are several ways to approach NLP, including:\\n- **Statistical NLP** : This approach uses statistical methods such as probability theory to assign meaning to words or phrases.\\n- **Rule-based NLP** : This approach uses predefined rules and patterns to understand language. These rules are based on the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Describe about stemming and lemmatize.\"\n",
        "qa.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM98-0Qlq53T",
        "outputId": "1d7473b1-6534-465e-e426-c7defb7f40aa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Describe about stemming and lemmatize.',\n",
              " 'result': \" Stemming and lemmatization are two different processes for reducing the words in a language to their root, which is the core part of a word that holds its primary meaning. However, they differ in how they achieve this. Stemming is a more straightforward process that removes prefixes and suffixes from words to reach the root, while lemmatization uses the language's grammar and vocabulary to reduce words to their root, often by changing the word according to the rules of the language. Lemmatization usually produces longer roots than stemming, as it tries to maintain the word's original meaning and grammatical properties, while stemming may produce roots that aren't actual words. \\n\\nBoth are often used in natural language processing to help computers understand and process large amounts of text, such as in text classification, information retrieval, and word similarity calculations. \"}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8eCtnOMCrPqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}