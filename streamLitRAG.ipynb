{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiQ9oSFLvnQ0"
      },
      "outputs": [],
      "source": [
        "!pip install virtualenv\n",
        "!mkdir my_virtualenv\n",
        "%cd my_virtualenv\n",
        "!virtualenv my_env\n",
        "!source my_env/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "psHxVkvsvoBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "# Set the app title\n",
        "st.title('My First Streamlit App')\n",
        "# Add a welcome message\n",
        "st.write('Welcome to my Streamlit app!')\n",
        "# Create a text input\n",
        "widgetuser_input = st.text_input('Enter a custom message:', 'Hello, Streamlit!')\n",
        "# Display the customized message\n",
        "st.write('Customized Message:', user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhn6c289v22V",
        "outputId": "a7212c4b-b49d-465f-d9ec-b1d1be8c46c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai langchain PyPDF2 faiss-cpu streamlit"
      ],
      "metadata": {
        "id": "P6nlDc5MwbfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet langchain-google-genai\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "BYxBoNeKGY_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import google.generativeai as palm\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.llms import GooglePalm\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] =  'AIzaSyAyL7Kf3lNM2TIHddoP4fR6xfpF8A'\n",
        "\n",
        "def get_pdf_text(pdf_docs):\n",
        "    text=\"\"\n",
        "    for pdf in pdf_docs:\n",
        "        pdf_reader= PdfReader(pdf)\n",
        "        for page in pdf_reader.pages:\n",
        "            text+= page.extract_text()\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "def get_vector_store(text_chunks):\n",
        "    embeddings = GooglePalmEmbeddings()\n",
        "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "    return vector_store\n",
        "\n",
        "def get_conversational_chain(vector_store):\n",
        "\n",
        "    #google_api_key=SECRET_KEY\n",
        "    llm = GoogleGenerativeAI(model=\"models/text-bison-001\", temperature=0.1)\n",
        "    #llm=GooglePalm()\n",
        "    memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True)\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=vector_store.as_retriever(), memory=memory)\n",
        "    return conversation_chain\n",
        "\n",
        "def user_input(user_question):\n",
        "    response = st.session_state.conversation({'question': user_question})\n",
        "    st.session_state.chatHistory = response['chat_history']\n",
        "    for i, message in enumerate(st.session_state.chatHistory):\n",
        "        if i%2 == 0:\n",
        "            st.write(\"Human: \", message.content)\n",
        "        else:\n",
        "            st.write(\"Bot: \", message.content)\n",
        "def main():\n",
        "    st.set_page_config(\"Chat with PDFs\")\n",
        "    st.header(\"Chat with PDF\")\n",
        "    user_question = st.text_input(\"Ask a Question from the PDF Files\")\n",
        "    if \"conversation\" not in st.session_state:\n",
        "        st.session_state.conversation = None\n",
        "    if \"chatHistory\" not in st.session_state:\n",
        "        st.session_state.chatHistory = None\n",
        "    if user_question:\n",
        "        user_input(user_question)\n",
        "    with st.sidebar:\n",
        "        st.title(\"Settings\")\n",
        "        st.subheader(\"Upload your Documents\")\n",
        "        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Process Button\", accept_multiple_files=True)\n",
        "        if st.button(\"Process\"):\n",
        "            with st.spinner(\"Processing\"):\n",
        "                raw_text = get_pdf_text(pdf_docs)\n",
        "                text_chunks = get_text_chunks(raw_text)\n",
        "                vector_store = get_vector_store(text_chunks)\n",
        "                st.session_state.conversation = get_conversational_chain(vector_store)\n",
        "                st.success(\"Done\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "aY09DA3hwbjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n"
      ],
      "metadata": {
        "id": "Hbs8GV7Uv_mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGQrGzrhx_Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/my_virtualenv/app1.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "OB-XG6qUwIdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houNxve-wBr2",
        "outputId": "304c7aae-62e3-4605-fa40-512f9183ffcb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.923s\n",
            "your url is: https://two-dingos-cry.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n"
      ],
      "metadata": {
        "id": "pFjFIxw7wNl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet langchain-google-genai\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "BInTFU-d8Bir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16V4DbtI84A7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}